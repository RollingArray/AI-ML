{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 (AdaBoost)\n",
    "\n",
    "Given data\n",
    "\n",
    "|x     | y   | Weight|\n",
    "------|------|----------\n",
    "0.1   | 1   | 0.1\n",
    "0.2   | 1   | 0.1\n",
    "0.3   | 1   | 0.1\n",
    "0.4   | -1  | 0.1\n",
    "0.5   | -1  | 0.1\n",
    "0.6   | -1  | 0.1\n",
    "0.7   | -1  | 0.1\n",
    "0.8   | 1   | 0.1\n",
    "0.9   | 1   | 0.1\n",
    "1     | 1   | 0.1\n",
    "\n",
    "## **Iteration 1**\n",
    "Step 1: Initialize weights\n",
    "Initially, each sample has equal weight, which is 1/10.\n",
    "\n",
    "Step 2: For each iteration:\n",
    "\n",
    "### a. Train a weak learner: We'll use a decision stump as our weak learner, which is essentially a decision tree with a single split.\n",
    "\n",
    "Let's say for the first iteration, the decision stump splits the data into two parts based on a threshold:\n",
    "\n",
    "```\n",
    "Threshold = 0.45\n",
    "Predictions:\n",
    "For x < 0.45: Predict 1\n",
    "For x >= 0.45: Predict -1\n",
    "```\n",
    "**Before Prediction:**\n",
    "| x    | y    | Weight |\n",
    "|------|------|--------|\n",
    "| 0.1  | 1    | 0.1    |\n",
    "| 0.2  | 1    | 0.1    |\n",
    "| 0.3  | 1    | 0.1    |\n",
    "| 0.4  | -1   | 0.1    |\n",
    "| 0.5  | -1   | 0.1    |\n",
    "| 0.6  | -1   | 0.1    |\n",
    "| 0.7  | -1   | 0.1    |\n",
    "| 0.8  | 1    | 0.1    |\n",
    "| 0.9  | 1    | 0.1    |\n",
    "| 1    | 1    | 0.1    |\n",
    "\n",
    "**After Prediction:**\n",
    "\n",
    "| x    | y    | Weight | Prediction |\n",
    "|------|------|--------|------------|\n",
    "| 0.1  | 1    | 0.1    | 1          |\n",
    "| 0.2  | 1    | 0.1    | 1          |\n",
    "| 0.3  | 1    | 0.1    | 1          |\n",
    "| 0.4  | -1   | 0.1    | 1          |\n",
    "| 0.5  | -1   | 0.1    | -1         |\n",
    "| 0.6  | -1   | 0.1    | -1         |\n",
    "| 0.7  | -1   | 0.1    | -1         |\n",
    "| 0.8  | 1    | 0.1    | -1         |\n",
    "| 0.9  | 1    | 0.1    | -1         |\n",
    "| 1    | 1    | 0.1    | -1         |\n",
    "\n",
    "In the \"After Prediction\" table, there are four misclassified samples:\n",
    "\n",
    "1. For x = 0.4, the true label is -1, but the prediction is 1.\n",
    "2. For x = 0.8, the true label is 1, but the prediction is -1.\n",
    "3. For x = 0.9, the true label is 1, but the prediction is -1.\n",
    "4. For x = 1, the true label is 1, but the prediction is -1.\n",
    "\n",
    "These samples are misclassified because they fall on the side of the threshold opposite to their true label. \n",
    "\n",
    "### b. Compute error: Error is computed as the weighted sum of misclassified samples.\n",
    "\n",
    "To calculate the error, we sum the weights of the misclassified samples and then divide by the sum of all weights. \n",
    "\n",
    "```\n",
    "Error = (Sum of weights of misclassified samples) / (Sum of all weights)\n",
    "```\n",
    "\n",
    "From the \"Before Prediction\" table:\n",
    "- Weights of misclassified samples: 0.1 (for x = 0.4), 0.1 (for x = 0.8), 0.1 (for x = 0.9), 0.1 (for x = 1)\n",
    "- Sum of weights of misclassified samples: 0.1 + 0.1 + 0.1 + 0.1 = 0.4\n",
    "\n",
    "Sum of all weights: 1.0\n",
    "\n",
    "```\n",
    "Error = 0.4 / 1.0 = 0.4\n",
    "```\n",
    "\n",
    "So, the error is 0.4 or 40%. This means 40% of the samples are misclassified based on the current weak learner's threshold of 0.45. \n",
    "\n",
    "### c. Compute weight of the weak learner: We use the error to compute the weight of the weak learner in the final model.\n",
    "\n",
    "To compute the weight of the weak learner in AdaBoost, we use the error of the weak learner. The formula to compute the weight of the weak learner is:\n",
    "\n",
    "$ \\text{Weight of weak learner} = \\frac{1}{2} \\ln\\left(\\frac{1 - \\text{error}}{\\text{error}}\\right) $\n",
    "\n",
    "Given that the error is 0.4 (as calculated previously):\n",
    "\n",
    "$ \\text{Weight of weak learner} = \\frac{1}{2} \\ln\\left(\\frac{1 - 0.4}{0.4}\\right) $\n",
    "\n",
    "$ \\text{Weight of weak learner} = \\frac{1}{2} \\ln\\left(\\frac{0.6}{0.4}\\right) $\n",
    "\n",
    "$ \\text{Weight of weak learner} = \\frac{1}{2} \\ln(1.5) $\n",
    "\n",
    "$ \\text{Weight of weak learner} = \\frac{1}{2} \\times 0.4055 $\n",
    "\n",
    "$ \\text{Weight of weak learner} = 0.2028 $\n",
    "\n",
    "So, the weight of the weak learner is approximately 0.2028.\n",
    "\n",
    "### d. Update weights: We update the weights of the samples, giving higher weight to misclassified samples.\n",
    "\n",
    "To update the weights of the samples, we use the following formulas:\n",
    "\n",
    "For correctly classified samples:\n",
    "$ \\text{New weight}_i = \\text{Old weight}_i \\times e^{-\\text{weight of weak learner}} $\n",
    "\n",
    "For misclassified samples:\n",
    "$ \\text{New weight}_i = \\text{Old weight}_i \\times e^{\\text{weight of weak learner}} $\n",
    "\n",
    "Let's calculate the updated weights and present them in the form of a table:\n",
    "\n",
    "| x    | y    | Weight |   Weight (Updated) |\n",
    "|------|------|--------|-------------------|\n",
    "| 0.1  | 1    | 0.1    |0.1 * exp(-0.2028) ≈ 0.0899 |\n",
    "| 0.2  | 1    | 0.1    |0.1 * exp(-0.2028) ≈ 0.0899 |\n",
    "| 0.3  | 1    | 0.1    |0.1 * exp(-0.2028) ≈ 0.0899 |\n",
    "| 0.4  | -1   | 0.1    |0.1 * exp(0.2028) ≈ 0.1111 |\n",
    "| 0.5  | -1   | 0.1    |0.1 * exp(0.2028) ≈ 0.1111 |\n",
    "| 0.6  | -1   | 0.1    |0.1 * exp(0.2028) ≈ 0.1111 |\n",
    "| 0.7  | -1   | 0.1    |0.1 * exp(0.2028) ≈ 0.1111 |\n",
    "| 0.8  | 1    | 0.1    |0.1 * exp(-0.2028) ≈ 0.0899 |\n",
    "| 0.9  | 1    | 0.1    |0.1 * exp(-0.2028) ≈ 0.0899 |\n",
    "| 1    | 1    | 0.1    |0.1 * exp(-0.2028) ≈ 0.0899 |\n",
    "\n",
    "## **Iteration 2**\n",
    "For the second iteration of AdaBoost, we follow the same steps as before:\n",
    "\n",
    "1. Train a weak learner.\n",
    "2. Compute the error.\n",
    "3. Compute the weight of the weak learner.\n",
    "4. Update the weights of the samples.\n",
    "\n",
    "Let's continue with the updated weights from the first iteration:\n",
    "\n",
    "**Updated Weights from First Iteration:**\n",
    "\n",
    "| x    | y    | Weight (Updated) |\n",
    "|------|------|-------------------|\n",
    "| 0.1  | 1    | 0.0899 |\n",
    "| 0.2  | 1    | 0.0899 |\n",
    "| 0.3  | 1    | 0.0899 |\n",
    "| 0.4  | -1   | 0.1111 |\n",
    "| 0.5  | -1   | 0.1111 |\n",
    "| 0.6  | -1   | 0.1111 |\n",
    "| 0.7  | -1   | 0.1111 |\n",
    "| 0.8  | 1    | 0.0899 |\n",
    "| 0.9  | 1    | 0.0899 |\n",
    "| 1    | 1    | 0.0899 |\n",
    "\n",
    "Now, let's proceed with the second iteration:\n",
    "\n",
    "**Weak Learner for Second Iteration:**\n",
    "Let's say we choose the split at x = 0.25.\n",
    "\n",
    "**Error Calculation:**\n",
    "```\n",
    "Error = (Sum of weights of misclassified samples) / (Sum of all weights)\n",
    "```\n",
    "From the updated weights:\n",
    "- Weights of misclassified samples: 0.0899 (for x = 0.1), 0.0899 (for x = 0.2)\n",
    "- Sum of weights of misclassified samples: 0.0899 + 0.0899 = 0.1798\n",
    "\n",
    "Sum of all weights: 1.0\n",
    "\n",
    "```\n",
    "Error = 0.1798 / 1.0 = 0.1798\n",
    "```\n",
    "\n",
    "**Weight of the Weak Learner:**\n",
    "```\n",
    "Weight of weak learner = 0.5 * ln((1 - error) / error)\n",
    "Weight of weak learner = 0.5 * ln((1 - 0.1798) / 0.1798)\n",
    "Weight of weak learner ≈ 0.881\n",
    "```\n",
    "\n",
    "**Updating Weights:**\n",
    "\n",
    "For correctly classified samples:\n",
    "$ \\text{New weight}_i = \\text{Old weight}_i \\times e^{-\\text{weight of weak learner}} $\n",
    "\n",
    "For misclassified samples:\n",
    "$ \\text{New weight}_i = \\text{Old weight}_i \\times e^{\\text{weight of weak learner}} $\n",
    "\n",
    "We'll update the weights accordingly and present them in a table.\n",
    "Sure, let's update the weights using the formulas mentioned earlier and present them in a table:\n",
    "\n",
    "| x    | y    | Weight (First Iteration) | Weight (Updated) |\n",
    "|------|------|---------------------------|-------------------|\n",
    "| 0.1  | 1    | 0.0899                    |0.0899 * exp(-0.881) ≈ 0.0451 |\n",
    "| 0.2  | 1    | 0.0899                    |0.0899 * exp(-0.881) ≈ 0.0451 |\n",
    "| 0.3  | 1    | 0.0899                    |0.0899 * exp(-0.881) ≈ 0.0451 |\n",
    "| 0.4  | -1   | 0.1111                    |0.1111 * exp(0.881) ≈ 0.2186 |\n",
    "| 0.5  | -1   | 0.1111                    |0.1111 * exp(0.881) ≈ 0.2186 |\n",
    "| 0.6  | -1   | 0.1111                    |0.1111 * exp(0.881) ≈ 0.2186 |\n",
    "| 0.7  | -1   | 0.1111                    |0.1111 * exp(0.881) ≈ 0.2186 |\n",
    "| 0.8  | 1    | 0.0899                    |0.0899 * exp(-0.881) ≈ 0.0451 |\n",
    "| 0.9  | 1    | 0.0899                    |0.0899 * exp(-0.881) ≈ 0.0451 |\n",
    "| 1    | 1    | 0.0899                    |0.0899 * exp(-0.881) ≈ 0.0451 |\n",
    "\n",
    "## **Iteration 3**\n",
    "\n",
    "**Weak Learner for Third Iteration:**\n",
    "Let's say we choose the split at x = 0.6.\n",
    "\n",
    "**Error Calculation:**\n",
    "```\n",
    "Error = (Sum of weights of misclassified samples) / (Sum of all weights)\n",
    "```\n",
    "From the updated weights:\n",
    "- Weights of misclassified samples: 0.0451 (for x = 0.8), 0.0451 (for x = 0.9), 0.0451 (for x = 1)\n",
    "- Sum of weights of misclassified samples: 0.0451 + 0.0451 + 0.0451 = 0.1353\n",
    "\n",
    "Sum of all weights: 1.0\n",
    "\n",
    "```\n",
    "Error = 0.1353 / 1.0 = 0.1353\n",
    "```\n",
    "\n",
    "**Weight of the Weak Learner:**\n",
    "```\n",
    "Weight of weak learner = 0.5 * ln((1 - error) / error)\n",
    "Weight of weak learner = 0.5 * ln((1 - 0.1353) / 0.1353)\n",
    "Weight of weak learner ≈ 0.851\n",
    "```\n",
    "\n",
    "**Updating Weights:**\n",
    "\n",
    "For correctly classified samples:\n",
    "\\[ \\text{New weight}_i = \\text{Old weight}_i \\times e^{-\\text{weight of weak learner}} \\]\n",
    "\n",
    "For misclassified samples:\n",
    "\\[ \\text{New weight}_i = \\text{Old weight}_i \\times e^{\\text{weight of weak learner}} \\]\n",
    "\n",
    "Let's update the weights accordingly and present them in a table.\n",
    "\n",
    "Certainly! Let's merge the \"Before Update\" and \"After Update\" tables to show the weights before and after the third iteration:\n",
    "\n",
    "| x    | y    | Weight (Second Iteration) | Weight (Updated) (Third Iteration) |\n",
    "|------|------|---------------------------|-------------------------------------|\n",
    "| 0.1  | 1    | 0.0451                    | 0.0451 * exp(-0.851) ≈ 0.0231                            |\n",
    "| 0.2  | 1    | 0.0451                    | 0.0451 * exp(-0.851) ≈ 0.0231                              |\n",
    "| 0.3  | 1    | 0.0451                    | 0.0451 * exp(-0.851) ≈ 0.0231                              |\n",
    "| 0.4  | -1   | 0.2186                    | 0.2186 * exp(0.851) ≈ 0.4679                              |\n",
    "| 0.5  | -1   | 0.2186                    | 0.2186 * exp(0.851) ≈ 0.4679                              |\n",
    "| 0.6  | -1   | 0.2186                    | 0.2186 * exp(0.851) ≈ 0.4679                              |\n",
    "| 0.7  | -1   | 0.2186                    | 0.2186 * exp(0.851) ≈ 0.4679                              |\n",
    "| 0.8  | 1    | 0.0451                    | 0.0451 * exp(-0.851) ≈ 0.0231                              |\n",
    "| 0.9  | 1    | 0.0451                    | 0.0451 * exp(-0.851) ≈ 0.0231                              |\n",
    "| 1    | 1    | 0.0451                    | 0.0451 * exp(-0.851) ≈ 0.0231                              |\n",
    "\n",
    "## **Summery**\n",
    "\n",
    "Here's the summary of the AdaBoost iterations:\n",
    "\n",
    "| Round | Split Point | Left Class | Right Class | Alpha   |\n",
    "|-------|-------------|------------|-------------|---------|\n",
    "| 1     | 0.45        | 1          | -1          | 0.4055  |\n",
    "| 2     | 0.25        | 1          | -1          | 0.881   |\n",
    "| 3     | 0.6         | 1          | -1          | 0.851   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2 (AdaBoost)\n",
    "\n",
    "<img src=\"images/adaboost_ex1-1.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-2.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-3.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-4.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-5.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-6.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-7.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-8.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-9.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-10.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-11.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-12.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-13.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-14.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-15.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-16.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-17.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-18.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-19.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-20.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-21.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-22.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"images/adaboost_ex1-23.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example (Gradient Boosting )\n",
    "\n",
    "We have below table of sample data with Height, Age and Gender as input variables and weight as the output variable. Target variable is Weight\n",
    "\n",
    "| Height | Age | Gender | Weight |\n",
    "|--------|-----|--------|--------|\n",
    "| 5.4    | 28  | Male   | 88     |\n",
    "| 5.2    | 26  | Female | 76     |\n",
    "| 5      | 28  | Female | 56     |\n",
    "| 5.6    | 25  | Male   | 73     |\n",
    "| 6      | 25  | Male   | 77     |\n",
    "| 4      | 22  | Female | 57     |\n",
    "\n",
    "## Solution\n",
    "\n",
    "If we assume that the average of weights of all the samples as our initial guess then 71.2 (88+76+56+73+77+57/6=71.2) would be our initial root node.\n",
    "\n",
    "Step 1: Building the Initial Tree:\n",
    "Create the root node with the initial guess as the prediction for all samples.\n",
    "\n",
    "| Height | Age | Gender | Weight | Predicted Weight 1 | Pseudo Residuals 1 |\n",
    "|--------|-----|--------|--------|--------------------|--------------------|\n",
    "| 5.4    | 28  | Male   | 88     | 71.2               | 88 - 71.2 = 16.8  |\n",
    "| 5.2    | 26  | Female | 76     | 71.2               | 76 - 71.2 = 4.8   |\n",
    "| 5      | 28  | Female | 56     | 71.2               | 56 - 71.2 = -15.2 |\n",
    "| 5.6    | 25  | Male   | 73     | 71.2               | 73 - 71.2 = 1.8   |\n",
    "| 6      | 25  | Male   | 77     | 71.2               | 77 - 71.2 = 5.8   |\n",
    "| 4      | 22  | Female | 57     | 71.2               | 57 - 71.2 = -14.2 |\n",
    "\n",
    "- Build a new tree to predict these residuals using input variables.\n",
    "- \n",
    "<img src=\"Images/gradient-boost-1.png\" width=\"100%\">\n",
    "\n",
    "- Scale the predictions of each tree by a learning rate (e.g., 0.1).\n",
    "- Combining the trees to make the new prediction. So, we start with initial prediction 71.2 and run the sample data down the new tree and sum them.\n",
    "  \n",
    "| Height | Age | Gender | Weight | Predicted weight 2       |\n",
    "|--------|-----|--------|--------|-----------------------|\n",
    "| 5.4    | 28  | Male   | 88     | 71.2+0.1*16.8=72.9    |       \n",
    "| 5.2    | 26  | Female | 76     | 71.2+0.1*(-5.2)=70.7  |            \n",
    "| 5      | 28  | Female | 56     | 71.2+0.1*(-5.2)=70.7  |            \n",
    "| 5.6    | 25  | Male   | 73     | 71.2+0.1*3.8=71.6     |         \n",
    "| 6      | 25  | Male   | 77     | 71.2+0.1*3.8=71.6     |         \n",
    "| 4      | 22  | Female | 57     | 71.2+0.1*(-14.2)=69.8 |\n",
    "\n",
    "If we observe the new predicted weights, we can see a small improvement in the result compared to the average weight from initial assumption. To further improve the result, we repeat the steps 2 and 3 and build another tree from the new pseudo residuals to predict the weights.\n",
    "\n",
    "| Height | Age | Gender | Weight | Predicted weight 2   | Pseudo Residuals 2 |\n",
    "|--------|-----|--------|--------|----------------------|--------------------\n",
    "| 5.4    | 28  | Male   | 88     | 72.9                 | 88-72.9= 15.1            \n",
    "| 5.2    | 26  | Female | 76     | 70.7                 | 76-70.7=5.3              \n",
    "| 5      | 28  | Female | 56     | 70.7                 | 56-70.7=-14.7           \n",
    "| 5.6    | 25  | Male   | 73     | 71.6                 | 73-71.6= 1.4      \n",
    "| 6      | 25  | Male   | 77     | 71.6                 | 77-71.6 =5.4      \n",
    "| 4      | 22  | Female | 57     | 69.8                 | 57-69.8=-12.8\n",
    "\n",
    "Again build a new tree with the new pseudo residuals.\n",
    "<img src=\"Images/gradient-boost-1.png\" width=\"100%\">\n",
    "\n",
    "Now we combine the new tree with all the previous trees to predict the new weights. So, we start with initial prediction and sum it with scaled result of 1st tree and then sum with scaled result of new tree.\n",
    "\n",
    "| Height | Age | Gender | Weight | Predicted weight 3                   |\n",
    "|--------|-----|--------|--------|--------------------------------------|\n",
    "| 5.4    | 28  | Male   | 88     | 71.2+0.1*16.8+0.1*15.1 = 74.4        |       \n",
    "| 5.2    | 26  | Female | 76     | 71.2+0.1*(-5.2)+0.1*(-4.7) = 70.2    |            \n",
    "| 5      | 28  | Female | 56     | 71.2+0.1*(-5.2)+0.1*(-4.7) = 70.2    |            \n",
    "| 5.6    | 25  | Male   | 73     | 71.2+0.1*3.8+0.1*3.4=71.9            |         \n",
    "| 6      | 25  | Male   | 77     | 71.2+0.1*3.8+0.1*3.4=71.9            |         \n",
    "| 4      | 22  | Female | 57     | 71.2+0.1*(-14.2)+0.1*(-12.8) = 68.5  |\n",
    "\n",
    "From the new predicted weight, we can observe there is further improvement in the result. Again we calculate the pseudo weights and build new tree in the similar way. These steps are repeated several times until the new tree doesn’t decrease the pseudo residual value or till maximum number of trees are built.\n",
    "\n",
    "So the final predicted model would be\n",
    "\n",
    "<img src=\"Images/gradient-boost-3.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c=\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
